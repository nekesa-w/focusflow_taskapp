{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "checkpoint = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subtasks(task_description, model, tokenizer, num_subtasks):\n",
    "    prompt = (\n",
    "        f\"You are a task planner. Break down the following task into exactly {num_subtasks} clear and actionable steps. \"\n",
    "        \"Each subtask should be practical, specific, and easy to follow. The subtasks should be ordered logically, \"\n",
    "        \"and should focus on accomplishing the task in a methodical way. Avoid any filler, general explanations, or placeholders. \"\n",
    "        \"The goal is for someone to be able to follow these steps and complete \"\n",
    "        \"the task without needing further clarification.\\n\\n\"\n",
    "        f\"Task: {task_description}\\n\\n\"\n",
    "        \"Subtasks:\"\n",
    "    )\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            no_repeat_ngram_size=2,\n",
    "            num_beams=1,\n",
    "            early_stopping=True,\n",
    "            max_new_tokens=256\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    subtasks_section = generated_text.split(\"Subtasks:\", 1)[-1].strip()\n",
    "    subtasks = []\n",
    "    \n",
    "    # Match valid subtasks that start with a number followed by a period and space\n",
    "    valid_subtask_regex = r\"^\\d+\\.\\s+\"\n",
    "\n",
    "    for line in subtasks_section.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if line and re.match(valid_subtask_regex, line):\n",
    "            subtask_text = re.sub(r\"^\\d+\\.\\s*\", \"\", line)  # Remove numbering\n",
    "            subtasks.append(subtask_text.strip())  # Add the subtask text\n",
    "\n",
    "    # Ensure exactly 'num_subtasks' subtasks, truncating if necessary\n",
    "    subtasks = subtasks[:num_subtasks]\n",
    "\n",
    "    # If there are fewer subtasks, fill in placeholders but avoid adding placeholders if it is an incomplete task\n",
    "    while len(subtasks) < num_subtasks:\n",
    "        subtasks.append(\"Complete the task.\")\n",
    "\n",
    "    return subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "subtasks = generate_subtasks(\"plan wedding\", model, tokenizer, num_subtasks=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Decide on the date of the wedding.\n",
      "2. Choose a venue.\n",
      "3. Create a guest list. Determine how many guests you can invite to your special day. Keep in mind that you'll need to accommodate guests with disabilities, as well as those with special dietary needs.\n",
      "4. Plan the menu. You'll want to decide on a menu that will satisfy your guests' tastes and dietary restrictions. Research local restaurants and consider factors like price, location, availability, quality, service, food quality and price. Also, consider the dietary requirements of your guest. For example, if you have guests who are gluten-free, you may need a gluten free menu or a substitute for gluten. If you're planning a vegetarian or vegan wedding, research restaurants that offer vegetarian and vegan options. Finally, decide whether you want a sit-down dinner, a buffet, appetizers, main course, dessert, wine, beer, cocktails,\n",
      "5. Placeholder.\n",
      "6. Placeholder.\n",
      "7. Placeholder.\n",
      "8. Placeholder.\n"
     ]
    }
   ],
   "source": [
    "for i, subtask in enumerate(subtasks, 1):\n",
    "    print(f\"{i}. {subtask}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
