{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"C:/xampp/htdocs/taskapp/llm/merged_model\"\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subtasks(task_title, model, tokenizer, num_subtasks, detail_level):\n",
    "    if detail_level == \"low\":\n",
    "        detail_instruction = \"Each subtask should be fewer than 5 words.\"\n",
    "    elif detail_level == \"high\":\n",
    "        detail_instruction = \"Each subtask should be between 20 to 30 words.\"\n",
    "    \n",
    "    prompt = (\n",
    "        f\"You are a task planner. Break down the following task into exactly {num_subtasks} clear and actionable steps. \"\n",
    "        f\"{detail_instruction} Each subtask should be practical, specific, and easy to follow. The subtasks should be ordered logically and focus on accomplishing the task in a methodical way. \"\n",
    "        \"Avoid any filler, general explanations, or placeholders. The goal is for someone to be able to follow these steps and complete the task without needing further clarification.\\n\\n\"\n",
    "        f\"Task: {task_title}\\n\\n\"\n",
    "        \"Subtasks:\"\n",
    "    )\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(\n",
    "            prompt, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        ).to(model.device)\n",
    "\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            no_repeat_ngram_size=2,\n",
    "            num_beams=1,\n",
    "            early_stopping=True,\n",
    "            max_new_tokens=256,\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    subtasks_section = generated_text.split(\"Subtasks:\", 1)[-1].strip()\n",
    "    subtasks_section = re.sub(r\"^\\d+\\.\\s*\", \"\", subtasks_section, flags=re.MULTILINE)\n",
    "\n",
    "    subtasks_list = [\n",
    "        sentence.strip() + \".\" for sentence in re.split(r'[.\\n]', subtasks_section) if sentence.strip()\n",
    "    ]\n",
    "\n",
    "    subtasks = subtasks_list[:num_subtasks]\n",
    "\n",
    "    while len(subtasks) < num_subtasks:\n",
    "        subtasks.append(\"Do remaining tasks\")\n",
    "\n",
    "    if detail_level == \"high\":\n",
    "        subtasks[-1] = \"Do remaining tasks\"\n",
    "\n",
    "    if num_subtasks > 5:\n",
    "        subtasks[-1] = \"Do remaining tasks\"\n",
    "\n",
    "    motivational_words_first = [\n",
    "        \"to begin the journey\",\n",
    "        \"to set the pace\",\n",
    "        \"to take the first step\",\n",
    "        \"to move forward\",\n",
    "        \"to start strong\",\n",
    "        \"to kick things off\",\n",
    "        \"to begin today\",\n",
    "        \"to make your first move\",\n",
    "        \"to set things in motion\",\n",
    "        \"to start progress\",\n",
    "        \"to take the first action\",\n",
    "        \"to begin the climb\",\n",
    "        \"to get moving\",\n",
    "        \"to start your path\",\n",
    "        \"to lay the foundation\",\n",
    "        \"to take the first leap\",\n",
    "        \"to make the first change\",\n",
    "        \"to start the first phase\",\n",
    "        \"to make the first mark\",\n",
    "    ]\n",
    "\n",
    "    motivational_words_middle = [\n",
    "        \"to keep the momentum going\",\n",
    "        \"to stay on track\",\n",
    "        \"to push through\",\n",
    "        \"to maintain your focus\",\n",
    "        \"to keep moving forward\",\n",
    "        \"to stay committed\",\n",
    "        \"to keep progressing\",\n",
    "        \"to keep up the good work\",\n",
    "        \"to build on your success\",\n",
    "        \"to keep up the pace\",\n",
    "        \"to get closer to your goal\",\n",
    "        \"to stay determined\",\n",
    "        \"to keep climbing\",\n",
    "        \"to stay in the game\",\n",
    "    ]\n",
    "\n",
    "    motivational_words_last = [\n",
    "        \"and finish strong\",\n",
    "        \"to complete the journey\",\n",
    "        \"and celebrate your success\",\n",
    "        \"to reach your goal\",\n",
    "        \"and take pride in your achievement\",\n",
    "        \"to close the chapter\",\n",
    "        \"and see your hard work pay off\",\n",
    "        \"and savor the victory\",\n",
    "        \"to seal the deal\",\n",
    "        \"and end on a high note\",\n",
    "        \"to finish what you started\",\n",
    "        \"and reap the rewards\",\n",
    "        \"to cross the finish line\",\n",
    "        \"and be proud of the result\",\n",
    "        \"to end with impact\",\n",
    "        \"and complete the mission\",\n",
    "        \"to wrap it all up\",\n",
    "    ]\n",
    "\n",
    "    for i, subtask in enumerate(subtasks):\n",
    "        if i == 0:\n",
    "            subtasks[i] = (\n",
    "                subtask.rstrip(\".\") + \" \" + random.choice(motivational_words_first)\n",
    "            )\n",
    "        elif i == len(subtasks) - 1:\n",
    "            subtasks[i] = (\n",
    "                subtask.rstrip(\".\") + \" \" + random.choice(motivational_words_last)\n",
    "            )\n",
    "        else:\n",
    "            subtasks[i] = (\n",
    "                subtask.rstrip(\".\") + \" \" + random.choice(motivational_words_middle)\n",
    "            )\n",
    "\n",
    "    return subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_title = \"plan halloween party\"\n",
    "num_subtasks = 10\n",
    "detail_level = \"low\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtasks = generate_subtasks(task_title, model, tokenizer, num_subtasks, detail_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subtask in subtasks:\n",
    "    print(subtask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
