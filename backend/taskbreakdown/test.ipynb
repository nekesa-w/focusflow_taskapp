{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "checkpoint = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" # for GPU usage or \"cpu\" for CPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subtasks(task_description, model, tokenizer, num_subtasks, detail_level):\n",
    "    prompt = (\n",
    "        f\"You are a task planner. Break down the following task into exactly {num_subtasks} clear and actionable steps. \"\n",
    "        \"Each subtask should be practical, specific, and easy to follow. The subtasks should be ordered logically, \"\n",
    "        \"and should focus on accomplishing the task in a methodical way. Avoid any filler, general explanations, or placeholders. \"\n",
    "        f\"The level of detail should be {'high' if detail_level == 'high' else 'low'}, meaning the subtasks should either \"\n",
    "        \"be thorough or concise, depending on the setting. The goal is for someone to be able to follow these steps and complete \"\n",
    "        \"the task without needing further clarification.\\n\\n\"\n",
    "        f\"Task: {task_description}\\n\\n\"\n",
    "        \"Subtasks:\"\n",
    "    )\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            no_repeat_ngram_size=2,\n",
    "            num_beams=1,\n",
    "            early_stopping=True,\n",
    "            max_new_tokens=256\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    subtasks_section = generated_text.split(\"Subtasks:\", 1)[-1].strip()\n",
    "    subtasks = []\n",
    "    \n",
    "    valid_subtask_regex = r\"^[0-9]+\\. .+\"  # Match lines that start with a number followed by a dot and a space\n",
    "    \n",
    "    for line in subtasks_section.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if line and re.match(valid_subtask_regex, line):\n",
    "            # Remove the numbering (the part before the first dot)\n",
    "            subtask_text = re.sub(r\"^\\d+\\.\\s*\", \"\", line)\n",
    "            subtasks.append(subtask_text.strip())\n",
    "\n",
    "    # Ensure exactly 'num_subtasks' subtasks\n",
    "    while len(subtasks) < num_subtasks:\n",
    "        subtasks.append(\"Placeholder.\")\n",
    "    subtasks = subtasks[:num_subtasks]  # If there are too many, truncate to the required number\n",
    "    \n",
    "    return subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "subtasks = generate_subtasks(\"plan wedding\", model, tokenizer, num_subtasks=5, detail_level='high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Decide on a date for the wedding.\n",
      "2. Choose a venue.\n",
      "3. Plan the ceremony. Create a detailed plan for how the couple will celebrate their union. This includes the order of events, music, speeches, gifts, attire, food, drinks, photography, videography, flowers, decorations, seating, lighting, sound, audio, technology, guests, timing, logistics, budget, timeline, vendors, volunteers, staff, security, parking, transportation, accommodations, insurance, permits, licenses, contracts, witnesses, officiant, photographer, florist, caterer, servers, bartenders, wait staffs, wedding party, bridesmaids, groomsmen, photographers, video editors, designers,\n",
      "4. Placeholder.\n",
      "5. Placeholder.\n"
     ]
    }
   ],
   "source": [
    "for i, subtask in enumerate(subtasks, 1):\n",
    "    print(f\"{i}. {subtask}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
